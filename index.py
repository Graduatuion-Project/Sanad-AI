import json
import os
import cv2
from camel_tools.tokenizers.word import simple_word_tokenize
from camel_tools.morphology.analyzer import Analyzer
from fuzzywuzzy import process
import fasttext

# ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ù„Ù„ Ø§Ù„Ø¬Ø°Ø± Ù…Ù† CAMeL Tools
analyzer = Analyzer.builtin("calima-msa")

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ FastText Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§)
fasttext_model = fasttext.load_model("cc.ar.300.bin")

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù† JSON
def load_dataset(json_file):
    with open(json_file, "r", encoding="utf-8") as f:
        return json.load(f)

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª
def tokenize_sentence(sentence):
    return simple_word_tokenize(sentence)  # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© ØµØ­ÙŠØ­Ø©

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CAMeL Tools
def get_root(word):
    analyses = analyzer.analyze(word)
    if analyses:
        return analyses[0].get("root", word)  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
    return word  # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø© ÙƒÙ…Ø§ Ù‡ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°ÙˆØ±
def preprocess_sentence(sentence):
    words = tokenize_sentence(sentence)  # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„Ø© Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª
    roots = [get_root(word) for word in words]  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„ØµØ­ÙŠØ­Ø©
    return roots

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ ÙƒÙ„Ù…Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Fuzzy Matching
def find_best_match(word, dataset):
    best_match, score = process.extractOne(word, dataset.keys())
    return best_match if score > 70 else None

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© Ø°Ø§Øª Ù…Ø¹Ù†Ù‰ Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FastText
def find_similar_word(word, dataset):
    similar_words = fasttext_model.get_nearest_neighbors(word)
    for similarity, similar_word in similar_words:
        if similar_word in dataset:
            return similar_word
    return None

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
def find_video(sentence, dataset):
    words = preprocess_sentence(sentence)  # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°ÙˆØ±
    for word in words:
        if word in dataset:
            return dataset[word]
        best_match = find_best_match(word, dataset)
        if best_match:
            return dataset[best_match]
        similar_word = find_similar_word(word, dataset)
        if similar_word:
            return dataset[similar_word]
    return None

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV
def play_video(video_path):
    if not os.path.exists(video_path):
        print("âŒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return
    
    cap = cv2.VideoCapture(video_path)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imshow("Video", frame)
        
        if cv2.waitKey(25) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
dataset = load_dataset("metadata.json")

# ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙÙŠØ¯ÙŠÙˆ Ù„Ø¬Ù…Ù„Ø© Ù…Ø¯Ø®Ù„Ø©
input_sentence = input("ğŸ” Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø©: ").strip()
video_path = find_video(input_sentence, dataset)

if video_path:
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_path}")
    play_video(video_path)
else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ù…Ø·Ø§Ø¨Ù‚!")
